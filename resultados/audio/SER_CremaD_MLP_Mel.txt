Classification Report
              precision    recall  f1-score   support

           0       0.28      0.20      0.23       255
           1       0.27      0.19      0.22       254
           2       0.41      0.55      0.47       254
           3       0.32      0.28      0.30       218
           4       0.26      0.26      0.26       254
           5       0.42      0.56      0.48       254

    accuracy                           0.34      1489
   macro avg       0.33      0.34      0.33      1489
weighted avg       0.33      0.34      0.33      1489

Confusion Matrix
[[ 50  22  71  28  36  48]
 [ 30  47  19  33  57  68]
 [ 24  13 140  31  34  12]
 [ 34  20  41  62  34  27]
 [ 25  28  63  26  66  46]
 [ 18  44   7  14  28 143]]

Test accuracy on folder 1
34.116856950973805

Classification Report
              precision    recall  f1-score   support

           0       0.27      0.20      0.23       254
           1       0.31      0.18      0.23       255
           2       0.39      0.52      0.45       255
           3       0.31      0.18      0.23       217
           4       0.23      0.31      0.26       254
           5       0.42      0.56      0.48       254

    accuracy                           0.33      1489
   macro avg       0.32      0.33      0.31      1489
weighted avg       0.32      0.33      0.32      1489

Confusion Matrix
[[ 51  13  55  26  56  53]
 [ 22  47  25  16  70  75]
 [ 34   8 133  19  48  13]
 [ 31  23  55  40  47  21]
 [ 30  28  64  19  78  35]
 [ 21  34   5   8  44 142]]

Test accuracy on folder 2
32.97515110812626

Classification Report
              precision    recall  f1-score   support

           0       0.23      0.24      0.24       254
           1       0.24      0.22      0.23       254
           2       0.39      0.43      0.41       254
           3       0.33      0.27      0.30       217
           4       0.23      0.21      0.22       255
           5       0.42      0.49      0.45       254

    accuracy                           0.31      1488
   macro avg       0.31      0.31      0.31      1488
weighted avg       0.31      0.31      0.31      1488

Confusion Matrix
[[ 61  36  53  25  32  47]
 [ 43  56  20  24  44  67]
 [ 44  13 108  37  42  10]
 [ 45  35  27  59  35  16]
 [ 39  46  59  25  54  32]
 [ 28  52   8  11  31 124]]

Test accuracy on folder 3
31.048387096774192

Classification Report
              precision    recall  f1-score   support

           0       0.29      0.27      0.28       254
           1       0.30      0.24      0.27       254
           2       0.42      0.56      0.48       254
           3       0.33      0.27      0.30       217
           4       0.28      0.27      0.27       254
           5       0.47      0.54      0.50       255

    accuracy                           0.36      1488
   macro avg       0.35      0.36      0.35      1488
weighted avg       0.35      0.36      0.35      1488

Confusion Matrix
[[ 69  25  69  18  27  46]
 [ 38  61  12  25  59  59]
 [ 40  12 143  26  28   5]
 [ 32  29  44  59  34  19]
 [ 27  28  69  37  68  25]
 [ 28  45   3  15  26 138]]

Test accuracy on folder 4
36.155913978494624

Classification Report
              precision    recall  f1-score   support

           0       0.28      0.20      0.24       254
           1       0.26      0.23      0.24       254
           2       0.42      0.54      0.47       254
           3       0.32      0.28      0.30       218
           4       0.28      0.21      0.24       254
           5       0.43      0.62      0.50       254

    accuracy                           0.35      1488
   macro avg       0.33      0.35      0.33      1488
weighted avg       0.33      0.35      0.33      1488

Confusion Matrix
[[ 52  33  80  24  20  45]
 [ 28  59  18  35  36  78]
 [ 28  13 138  37  30   8]
 [ 33  43  33  61  22  26]
 [ 23  46  54  23  53  55]
 [ 20  34   5  10  28 157]]

Test accuracy on folder 5
34.946236559139784


SUMMARY

Mean accuracy
33.84850913870173

F1-Score
32.72761826725159

Precision
32.70356079027231

Recall
33.84850913870173

Confusion Matrix
[[ 56  25  65  24  34  47]
 [ 32  54  18  26  53  69]
 [ 34  11 132  30  36   9]
 [ 35  30  40  56  34  21]
 [ 28  35  61  26  63  38]
 [ 23  41   5  11  31 140]]